import os
import joblib
import numpy as np
import dask.dataframe as dd
from dask_ml.model_selection import train_test_split
import xgboost as xgb
from xgboost import dask as dxgb

# Ki√©rt√©kel√©si metrik√°k
from sklearn.metrics import (
    root_mean_squared_error, recall_score, f1_score,
    jaccard_score, confusion_matrix, accuracy_score
)


class XGBoostTrainer:
    def __init__(self, csv_file_path, resource_folder, config, client):
        self.csv_file_path = csv_file_path
        self.resource_folder = resource_folder
        self.config = config
        self.client = client

    def train(self, log_callback, do_split=True):
        """
        do_split: Ha True, 80/20 ar√°nyban tesztel. Ha False, 100% adaton tan√≠t.
        """
        if not os.path.exists(self.csv_file_path):
            log_callback(f"‚ö†Ô∏è Nem tal√°lhat√≥ {self.csv_file_path} f√°jl.")
            return False

        try:
            log_callback(f"‚è≥ Adatok bet√∂lt√©se a {'Teszt' if do_split else 'V√©gleges'} m√≥dhoz...")
            origin_ddf = dd.read_csv(self.csv_file_path)

            # Tiszt√≠t√°s
            for col in ['Unnamed: 0.1', 'Unnamed: 0']:
                if col in origin_ddf.columns:
                    origin_ddf = origin_ddf.drop(columns=[col])

            y = origin_ddf['Label'].astype('int')
            X = origin_ddf.drop(['Label', 'patient_id'], axis=1)

            # --- M√≥d v√°laszt√°s: Split vagy Full ---
            if do_split:
                log_callback("‚úÇÔ∏è Adatok feloszt√°sa: 80% Tan√≠t√≥, 20% Teszt.")
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
                dtrain = dxgb.DaskDMatrix(self.client, X_train, y_train)
                dtest = dxgb.DaskDMatrix(self.client, X_test, y_test)
            else:
                log_callback("üöÄ V√©gleges m√≥d: Az √∂sszes adat (100%) felhaszn√°l√°sa tan√≠t√°shoz.")
                dtrain = dxgb.DaskDMatrix(self.client, X, y)
                dtest = None

            # Param√©terek
            params = {
                'objective': 'multi:softprob',
                'num_class': 15,
                'eval_metric': 'mlogloss',
                'max_depth': 4,
                'eta': 0.02,
                'subsample': 0.7,
                'colsample_bytree': 0.7,
                'tree_method': 'hist',
                'max_bin': 256,
            }

            log_callback("üöÄ XGBoost tan√≠t√°s ind√≠t√°sa...")
            model = dxgb.train(
                self.client,
                params,
                dtrain,
                num_boost_round=1000,
                evals=[(dtrain, "train")]
            )

            booster = model["booster"]

            # Ment√©s
            # Ha v√©gleges, adjunk egy '_final' jelz√©st a f√°jln√©vhez (opcion√°lis, de hasznos)
            base_name = self.config['model-name']
            if not do_split:
                base_name = base_name.replace(".pkl", "_final.pkl")

            pkl_path = f"{self.resource_folder}/{base_name}"

            if os.path.exists(pkl_path):
                os.remove(pkl_path)

            joblib.dump(booster, pkl_path)
            log_callback(f"üíæ Modell elmentve: {pkl_path}")

            # --- Ki√©rt√©kel√©s (csak ha k√©rt√ºnk tesztel√©st) ---
            if do_split and dtest is not None:
                log_callback("üìä Ki√©rt√©kel√©s a tesztadatokon...")
                y_dask_pred = dxgb.predict(self.client, booster, dtest)

                # Sz√°m√≠t√°sok
                y_pred_prob = y_dask_pred.compute()
                y_pred = np.argmax(y_pred_prob, axis=1)
                y_true = y_test.compute().to_numpy()

                # Metrik√°k
                accuracy = accuracy_score(y_true, y_pred)
                recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)
                f1 = f1_score(y_true, y_pred, average='macro')
                rmse = root_mean_squared_error(y_true, y_pred)
                conf_matrix = confusion_matrix(y_true, y_pred)

                log_callback('-' * 45)
                log_callback(f"üèÜ EREDM√âNYEK (80/20 SPLIT):")
                log_callback(f"   Pontoss√°g (Accuracy): {accuracy * 100:.2f}%")
                log_callback(f"   Recall (Weighted):    {recall:.4f}")
                log_callback(f"   F1 Score (Macro):     {f1:.4f}")
                log_callback(f"   RMSE:                 {rmse:.4f}")
                log_callback(f"   Confusion Matrix:\n{conf_matrix}")
                log_callback('-' * 45)
            else:
                log_callback("‚ÑπÔ∏è V√©gleges tan√≠t√°s befejezve. Nincs tesztel√©si f√°zis.")

            return True

        except Exception as e:
            log_callback(f"‚ùå Hiba a tan√≠t√°s sor√°n: {str(e)}")
            import traceback
            log_callback(traceback.format_exc())
            return False