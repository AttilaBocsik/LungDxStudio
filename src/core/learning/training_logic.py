import os
import joblib
import dask.dataframe as dd
from dask_ml.model_selection import train_test_split
import xgboost as xgb
from xgboost import dask as dxgb


class XGBoostTrainer:
    def __init__(self, csv_file_path, resource_folder, config, client):
        self.csv_file_path = csv_file_path
        self.resource_folder = resource_folder
        self.config = config
        self.client = client
        self.stop_requested = False  # Lehet≈ës√©g a meg√°ll√≠t√°sra

    def train(self, log_callback):
        """
        A log_callback egy f√ºggv√©ny, amit megh√≠vunk, ha √ºzenni akarunk a GUI-nak.
        """
        if not os.path.exists(self.csv_file_path):
            log_callback(f"‚ö†Ô∏è Nem tal√°lhat√≥ {self.csv_file_path} f√°jl.")
            return False  # Hib√°val t√©r√ºnk vissza

        try:
            log_callback("‚è≥ Adatok bet√∂lt√©se √©s el≈ëk√©sz√≠t√©se Dask seg√≠ts√©g√©vel...")

            origin_ddf = dd.read_csv(self.csv_file_path)
            # √öjraparticion√°l√°s, ha sz√ºks√©ges (CPU magok sz√°m√°t√≥l f√ºgg≈ëen)
            origin_ddf = origin_ddf.repartition(npartitions=2)

            # Felesleges oszlopok tiszt√≠t√°sa
            for col in ['Unnamed: 0.1', 'Unnamed: 0']:
                if col in origin_ddf.columns:
                    origin_ddf = origin_ddf.drop(columns=[col])

            # Label √©s Feature sz√©tv√°laszt√°s
            y = origin_ddf['Label'].astype('int')
            # pi = origin_ddf['patient_id'] # Ha nem haszn√°ljuk a tr√©ninghez, itt nem kell t√°rolni
            X = origin_ddf.drop(['Label', 'patient_id'], axis=1)

            # Split
            log_callback("‚úÇÔ∏è Adatok feloszt√°sa (80% Train - 20% Test)...")
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

            # Mem√≥ria tiszt√≠t√°s (Dask-n√°l a lazy eval miatt ez kev√©sb√© kritikus, de nem √°rt)
            del origin_ddf

            # Param√©terek
            params = {
                'objective': 'multi:softprob',
                'num_class': 15,
                'eval_metric': 'mlogloss',
                'max_depth': 4,
                'eta': 0.02,
                'subsample': 0.7,
                'colsample_bytree': 0.7,
                'tree_method': 'hist',  # CPU-n kritikus
                'max_bin': 256,
            }

            log_callback("‚öôÔ∏è Dask DMatrix el≈ëk√©sz√≠t√©se...")
            dtrain = dxgb.DaskDMatrix(self.client, X_train, y_train)
            # dtest = dxgb.DaskDMatrix(self.client, X_test, y_test) # Opcion√°lis valid√°ci√≥hoz

            log_callback("üöÄ Modell tan√≠t√°s√°nak ind√≠t√°sa (ez eltarthat egy ideig)...")

            num_round = 1000
            model = dxgb.train(
                self.client,
                params,
                dtrain,
                num_boost_round=num_round,
                evals=[(dtrain, "train")]
            )

            booster = model["booster"]

            # Ment√©s
            pkl_path = f"{self.resource_folder}/{self.config['model-name']}"

            if os.path.exists(pkl_path):
                os.remove(pkl_path)
                log_callback(f"‚ôªÔ∏è R√©gi modell t√∂r√∂lve: {pkl_path}")

            log_callback(f"üíæ √öj modell ment√©se ide: {pkl_path} ...")
            joblib.dump(booster, pkl_path)

            log_callback("‚úÖ Modell sikeresen l√©trehozva √©s elmentve.")
            return True

        except Exception as e:
            log_callback(f"‚ùå Hiba t√∂rt√©nt a tan√≠t√°s sor√°n: {str(e)}")
            return False