# src/core/learning/feature_extractor.py
import os
import glob
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from scipy import ndimage as nd
from skimage.filters import sobel


class FeatureExtractor:
    """
    KÃ©pjellemzÅ‘k kinyerÃ©sÃ©Ã©rt Ã©s adathalmaz Ã¶sszeÃ¡llÃ­tÃ¡sÃ¡Ã©rt felelÅ‘s osztÃ¡ly.

    Ez az osztÃ¡ly .npz fÃ¡jlokbÃ³l olvassa be a szegmentÃ¡lt CT kÃ©peket, kÃ¼lÃ¶nbÃ¶zÅ‘
    kÃ©pfeldolgozÃ³ szÅ±rÅ‘ket (Gabor, Sobel, Gauss, stb.) alkalmaz rajtuk pixel-szinten,
    majd az eredmÃ©nyeket egy strukturÃ¡lt pandas DataFrame-be gyÅ±jti Ã¶ssze a gÃ©pi tanulÃ¡shoz.

    Attributes:
        data_dir (str): A feldolgozott (.npz) fÃ¡jlok forrÃ¡skÃ¶nyvtÃ¡ra.
        gabor_kernels (list): A generÃ¡lt Gabor-szÅ±rÅ‘ magok listÃ¡ja.
    """

    def __init__(self, data_dir="processed_data"):
        """
        InicializÃ¡lja a FeatureExtractor-t Ã©s legenerÃ¡lja a szÅ±rÅ‘magokat.

        Args:
            data_dir (str, optional): A bemeneti adatok mappÃ¡ja. AlapÃ©rtelmezett: "processed_data".
        """
        self.data_dir = data_dir
        self.gabor_kernels = self.create_gabor_kernels()
        print(f"âœ… FeatureExtractor inicializÃ¡lva. Gabor kernelek szÃ¡ma: {len(self.gabor_kernels)}")

    @staticmethod
    def create_gabor_kernels():
        """
        Gabor-szÅ±rÅ‘ magok (kernels) generÃ¡lÃ¡sa kÃ¼lÃ¶nbÃ¶zÅ‘ paramÃ©terekkel.

        Returns:
            list: OpenCV Gabor kernel objektumok listÃ¡ja.
        """
        kernels = []
        ksize = 3
        thetas = [0, np.pi / 4]
        sigmas = [1, 3]
        lamdas = [np.pi / 4, np.pi / 2, 3 * np.pi / 4, np.pi]
        gammas = [0.05, 0.5]
        psi = 0
        for theta in thetas:
            for sigma in sigmas:
                for lamda in lamdas:
                    for gamma in gammas:
                        kernel = cv2.getGaborKernel(
                            (ksize, ksize), sigma, theta, lamda, gamma, psi, ktype=cv2.CV_32F
                        )
                        kernels.append(kernel)
        return kernels

    @staticmethod
    def remove_null_rows(df: pd.DataFrame) -> pd.DataFrame:
        """
        EltÃ¡volÃ­tja a hÃ¡ttÃ©rnek minÅ‘sÃ¼lÅ‘ (0 Ã©rtÃ©kÅ±) pixeleket a tÃ¡blÃ¡zatbÃ³l.

        Args:
            df (pd.DataFrame): A bemeneti jellemzÅ‘tÃ¡bla.

        Returns:
            pd.DataFrame: A megtisztÃ­tott tÃ¡blÃ¡zat, amely csak relevÃ¡ns pixeleket tartalmaz.
        """
        if df.empty:
            return df

        # 1. StratÃ©gia: Ha az EREDETI pixel (Image oszlop) 0, akkor az hÃ¡ttÃ©r.
        if 'Image' in df.columns:
            # Csak azokat tartjuk meg, ahol az eredeti kÃ©p abszolÃºt Ã©rtÃ©ke nagyobb mint 0
            # (1e-6 a lebegÅ‘pontos hibÃ¡k miatt biztonsÃ¡gosabb mint a sima 0)
            df_cleaned = df[df['Image'].abs() > 1e-6]
            return df_cleaned

        # 2. StratÃ©gia (Fallback): Ha valamiÃ©rt nincs Image oszlop
        middle_cols = df.iloc[:, 1:-2]
        condition = ((middle_cols == 0) | (middle_cols.isna())).all(axis=1)
        df_cleaned = df[~condition]
        return df_cleaned

    @staticmethod
    def select_random_rows(df: pd.DataFrame, selected_values: list, n_limit: int = 2000) -> pd.DataFrame:
        """
        VÃ©letlenszerÅ± mintavÃ©telezÃ©s (downsampling) a kiegyensÃºlyozott adathalmazÃ©rt.

        CÃ­mkÃ©nkÃ©nt korlÃ¡tozza a pixelek szÃ¡mÃ¡t, hogy a modell ne tanuljon el rÃ©szrehajlÃ¡st
        a tÃºlreprezentÃ¡lt osztÃ¡lyok irÃ¡nyÃ¡ba.

        Args:
            df (pd.DataFrame): ForrÃ¡s adatok.
            selected_values (list): A megtartandÃ³ Label Ã©rtÃ©kek listÃ¡ja.
            n_limit (int): MaximÃ¡lis mintaszÃ¡m cÃ­mkÃ©nkÃ©nt. AlapÃ©rtelmezett: 2000.

        Returns:
            pd.DataFrame: A mintavÃ©telezett adathalmaz.
        """
        if df.empty:
            return df

        filtered_dfs = []
        for value in selected_values:
            temp_df = df[df['Label'] == value]
            if not temp_df.empty:
                # Ha kevesebb pixel van, mint a limit, az Ã¶sszeset kÃ©ri,
                # ha tÃ¶bb, akkor pontosan n_limit darabot.
                count = min(n_limit, len(temp_df))
                sampled_df = temp_df.sample(n=count, random_state=42)
                filtered_dfs.append(sampled_df)

        if not filtered_dfs:
            return pd.DataFrame(columns=df.columns)

        return pd.concat(filtered_dfs).sort_index()

    def multi_filter(self, patient_id, img, tumor_type, lung_state):
        """
        KÃ¼lÃ¶nbÃ¶zÅ‘ digitÃ¡lis kÃ©pszÅ±rÅ‘k alkalmazÃ¡sa egy adott kÃ©pre.

        LÃ©trehozza a jellemzÅ‘vektorokat: Gabor-vÃ¡laszok, Sobel-Ã©lkeresÃ©s,
        Gauss-simÃ­tÃ¡s, mediÃ¡n szÅ±rÅ‘ Ã©s variancia. HozzÃ¡rendeli a megfelelÅ‘
        cÃ­mkÃ©t (Label) a tÃ¼dÅ‘ Ã¡llapota Ã©s a daganat tÃ­pusa alapjÃ¡n.

        Args:
            patient_id (str): A pÃ¡ciens azonosÃ­tÃ³ja.
            img (np.ndarray): A bemeneti kÃ©p (pixel array).
            tumor_type (str): A daganat tÃ­pusa (A, B, G, D).
            lung_state (str): A szÃ¶vet tÃ­pusa (pl. 'diseased_lungs', 'healthy_soft_tissue').

        Returns:
            pd.DataFrame: Egy tÃ¡blÃ¡zat, ahol minden sor egy pixel, az oszlopok pedig a szÅ±rt Ã©rtÃ©kek.
        """
        # MÃ¡solat kÃ©szÃ­tÃ©se
        img2 = img.copy()

        df = pd.DataFrame()

        # 1. Oszlop: Eredeti pixel Ã©rtÃ©kek
        df["Image"] = img2.reshape(-1)

        # 2. Gabor szÅ±rÅ‘k
        num = 1
        for gabor in self.gabor_kernels:
            gabor_label = 'Gabor' + str(num)
            fimg = cv2.filter2D(img2.astype('float32'), cv2.CV_32F, gabor)
            df[gabor_label] = fimg.reshape(-1)
            num += 1

        # 3. EgyÃ©b szÅ±rÅ‘k
        df['Sobel'] = sobel(img2).reshape(-1)
        df['Gaussian_s3'] = nd.gaussian_filter(img2, sigma=3).reshape(-1)
        df['Gaussian_s7'] = nd.gaussian_filter(img2, sigma=7).reshape(-1)
        df['Median_s3'] = nd.median_filter(img2, size=3).reshape(-1)
        df['Variance_s3'] = nd.generic_filter(img2, np.var, size=3).reshape(-1)

        # --- CÃ­mkÃ©zÃ©s ---
        label_value = 0
        if lung_state == "healthy_lungs":
            label_value = 1
        elif lung_state == "diseased_lungs":
            if tumor_type == 'A':
                label_value = 4
            elif tumor_type == 'B':
                label_value = 5
            elif tumor_type == 'D':
                label_value = 6
            elif tumor_type == 'G':
                label_value = 7
        elif lung_state == "healthy_soft_tissue":
            label_value = 1
        elif lung_state == "diseased_soft_tissue":
            if tumor_type == 'A':
                label_value = 8
            elif tumor_type == 'B':
                label_value = 10
            elif tumor_type == 'D':
                label_value = 12
            elif tumor_type == 'G':
                label_value = 14

        df["Label"] = label_value
        # JAVÃTÃS: BiztosÃ­tjuk, hogy a patient_id minden sorba bekerÃ¼ljÃ¶n
        df["patient_id"] = str(patient_id)

        return df

    def extract_features(self):
        """
        A teljes jellemzÅ‘kinyerÃ©si folyamat vezÃ©rlÃ©se.

        VÃ©gigmegy az Ã¶sszes .npz fÃ¡jlon, vÃ©grehajtja a szÅ±rÃ©st, a tisztÃ­tÃ¡st Ã©s a
        mintavÃ©telezÃ©st, majd Ã¶sszevont statisztikÃ¡t kÃ©szÃ­t a pÃ¡ciensekrÅ‘l.

        Returns:
            pd.DataFrame: Az Ã¶sszesÃ­tett, kevert (shuffled) tanÃ­tÃ³ adathalmaz.
        """
        npz_files = glob.glob(os.path.join(self.data_dir, "*.npz"))

        if not npz_files:
            print("âŒ Nincsenek .npz fÃ¡jlok a processed_data mappÃ¡ban.")
            return None

        print(f"ğŸ”„ JellemzÅ‘k kinyerÃ©se {len(npz_files)} fÃ¡jlbÃ³l...")

        dfs_to_merge = []

        for file_path in tqdm(npz_files, desc="FeldolgozÃ¡s"):
            try:
                with np.load(file_path) as data:
                    img_original = data['original']
                    img_parenchyma = data['parenchyma']
                    img_tumor = data['masked_tumor']
                    img_roi_context = data['inverted_roi']
                    label = str(data['label'])

                    # PÃ¡ciens ID tisztÃ­tÃ¡sa
                    raw_id = data['patient_id']
                    p_id = str(raw_id).replace("['", "").replace("']", "")

                # --- MintavÃ©telezÃ©s (SzeletenkÃ©nt Ã©s kÃ©ptÃ­pusonkÃ©nt 2000 minta) ---

                # A) Beteg tÃ¼dÅ‘
                df_orig = self.multi_filter(p_id, img_original, label, lung_state="diseased_lungs")
                df_orig = self.remove_null_rows(df_orig)
                df_orig = self.select_random_rows(df_orig, [0, 4, 5, 6, 7], n_limit=2000)

                # B) EgÃ©szsÃ©ges tÃ¼dÅ‘
                df_par = self.multi_filter(p_id, img_parenchyma, label, lung_state="healthy_lungs")
                df_par = self.remove_null_rows(df_par)
                df_par = self.select_random_rows(df_par, [0, 1], n_limit=2000)

                # C) Daganat
                df_tum = self.multi_filter(p_id, img_tumor, label, lung_state="diseased_soft_tissue")
                df_tum = self.remove_null_rows(df_tum)
                df_tum = self.select_random_rows(df_tum, [0, 8, 10, 12, 14], n_limit=2000)

                # D) ROI Context
                df_roi = self.multi_filter(p_id, img_roi_context, label, lung_state="healthy_soft_tissue")
                df_roi = self.remove_null_rows(df_roi)
                df_roi = self.select_random_rows(df_roi, [0, 1], n_limit=2000)

                dfs_to_merge.extend([df_orig, df_par, df_tum, df_roi])

            except Exception as e:
                print(f"âš ï¸ Hiba a fÃ¡jlnÃ¡l ({os.path.basename(file_path)}): {e}")

        if dfs_to_merge:
            print("\nğŸ“Š Adatok egyesÃ­tÃ©se Ã©s vÃ©gsÅ‘ simÃ­tÃ¡sok...")
            df_all = pd.concat(dfs_to_merge, ignore_index=True)

            # TisztÃ­tÃ¡s
            df_all.loc[df_all['Image'] == 0.0, 'Label'] = 0

            # --- STATISZTIKA KÃ‰SZÃTÃ‰SE ---
            print("\n" + "=" * 50)
            print("        ğŸ“Š PÃCIENS SZINTÅ° STATISZTIKA")
            print("=" * 50)

            # MegszÃ¡moljuk, melyik pÃ¡ciensbÅ‘l hÃ¡ny sor (pixel) kerÃ¼lt be
            stats = df_all['patient_id'].value_counts()

            for p_name, count in stats.items():
                # KiszÃ¡moljuk a daganatos pixelek arÃ¡nyÃ¡t is az adott pÃ¡ciensnÃ©l
                p_data = df_all[df_all['patient_id'] == p_name]
                tumor_pixels = len(p_data[p_data['Label'] > 1])
                print(f"ğŸ‘¤ PÃ¡ciens: {p_name:<20} | Ã–sszes pixel: {count:>6} | Daganatos: {tumor_pixels:>6}")

            print("-" * 50)
            print(f"ğŸ“ˆ Ã–SSZESEN: {len(df_all)} sor a CSV fÃ¡jlban.")
            print("=" * 50 + "\n")

            # KeverÃ©s (Shuffle)
            print("ğŸ”€ Adatok Ã¶sszekeverÃ©se...")
            df_all = df_all.sample(frac=1).reset_index(drop=True)

            return df_all
        else:
            return pd.DataFrame()

    def save_to_csv(self, df, output_path="training_data_pixelwise.csv"):
        """MentÃ©s CSV-be."""
        if df is not None and not df.empty:
            df.to_csv(output_path, index=False)
            print(f"ğŸ’¾ Mentve: {output_path}")
        else:
            print("âš ï¸ Nincs mit menteni (Ã¼res DataFrame).")
